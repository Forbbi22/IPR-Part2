{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVxEAuh1tBjP",
        "outputId": "b061e29e-ae9f-4c51-b58e-8b18fc9ae9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'multispectral-object-detection'...\n",
            "remote: Enumerating objects: 435, done.\u001b[K\n",
            "remote: Counting objects: 100% (252/252), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 435 (delta 176), reused 182 (delta 128), pack-reused 183 (from 1)\u001b[K\n",
            "Receiving objects: 100% (435/435), 42.83 MiB | 19.62 MiB/s, done.\n",
            "Resolving deltas: 100% (206/206), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Forbbi/multispectral-object-detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/dataset__llvip /content/multispectral-object-detection"
      ],
      "metadata": {
        "id": "tWZ5F6lStMBt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/multispectral-object-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeYbNngjtdZC",
        "outputId": "b92b165d-2d80-445c-880a-0a0b8ace9188"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multispectral-object-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eiNSytyOuSl9",
        "outputId": "66190b80-73bf-443f-d608-47d01f040488"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (10.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (4.66.6)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.17.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (2.2.2)\n",
            "Collecting thop (from -r requirements.txt (line 28))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (2.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.0->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 20)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 20)) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall wandb -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWdDWMKmuW8x",
        "outputId": "0a51510c-659f-4b68-8783-17c3ce33235d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: wandb 0.18.5\n",
            "Uninstalling wandb-0.18.5:\n",
            "  Successfully uninstalled wandb-0.18.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --weights yolov5l.pt --data data/multispectral/LLVIP.yaml --cfg models/transformer/yolov5l_fusion_transformerx3_llvip.yaml --epochs 50 --batch-size 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvXpteVhufHN",
        "outputId": "b7c0622c-b132-4e20-fd81-a5557af8cdd7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-03 11:49:33.501745: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-03 11:49:33.534794: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-03 11:49:33.545856: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-03 11:49:33.569826: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-03 11:49:35.424659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOv5 ðŸš€ 914f937 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n",
            "\n",
            "Namespace(weights='yolov5l.pt', cfg='models/transformer/yolov5l_fusion_transformerx3_llvip.yaml', data='data/multispectral/LLVIP.yaml', hyp='data/hyp.scratch.yaml', epochs=50, batch_size=8, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', world_size=1, global_rank=-1, save_dir='runs/train/exp2', total_batch_size=8)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "/content/multispectral-object-detection/train.py:498: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  run_id = torch.load(weights).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
            "/content/multispectral-object-detection/train.py:514: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  1   1611264  models.common.C3                        [256, 256, 9]                 \n",
            "  5                -4  1      7040  models.common.Focus                     [3, 64, 3]                    \n",
            "  6                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  7                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  8                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  9                -1  1   1611264  models.common.C3                        [256, 256, 9]                 \n",
            " 10            [4, 9]  1   6351360  models.common.GPT                       [256]                         \n",
            " 11           [4, 10]  1         0  models.common.Add2                      [256, 0]                      \n",
            " 12           [9, 10]  1         0  models.common.Add2                      [256, 1]                      \n",
            " 13                11  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            " 14                -1  1   6433792  models.common.C3                        [512, 512, 9]                 \n",
            " 15                12  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            " 16                -1  1   6433792  models.common.C3                        [512, 512, 9]                 \n",
            " 17          [14, 16]  1  25285632  models.common.GPT                       [512]                         \n",
            " 18          [14, 17]  1         0  models.common.Add2                      [512, 0]                      \n",
            " 19          [16, 17]  1         0  models.common.Add2                      [512, 1]                      \n",
            " 20                18  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 21                -1  1   2624512  models.common.SPPF                      [1024, 1024, [5, 9, 13]]      \n",
            " 22                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 23                19  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 24                -1  1   2624512  models.common.SPPF                      [1024, 1024, [5, 9, 13]]      \n",
            " 25                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 26          [22, 25]  1 100902912  models.common.GPT                       [1024]                        \n",
            " 27          [22, 26]  1         0  models.common.Add2                      [1024, 0]                     \n",
            " 28          [25, 26]  1         0  models.common.Add2                      [1024, 1]                     \n",
            " 29          [11, 12]  1         0  models.common.Add                       [256]                         \n",
            " 30          [18, 19]  1         0  models.common.Add                       [512]                         \n",
            " 31          [27, 28]  1         0  models.common.Add                       [1024]                        \n",
            " 32                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 34          [-1, 30]  1         0  models.common.Concat                    [1]                           \n",
            " 35                -1  1   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 36                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 38          [-1, 29]  1         0  models.common.Concat                    [1]                           \n",
            " 39                -1  1    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 40                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 41          [-1, 36]  1         0  models.common.Concat                    [1]                           \n",
            " 42                -1  1   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 43                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 44          [-1, 32]  1         0  models.common.Concat                    [1]                           \n",
            " 45                -1  1   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 46      [39, 42, 45]  1     32310  models.yolo_test.Detect                 [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 1189 layers, 206247222 parameters, 206247222 gradients\n",
            "\n",
            "Transferred 158/1445 items from yolov5l.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 372 .bias, 372 conv.weight, 174 other\n",
            "/content/multispectral-object-detection/utils/datasets.py:908: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cache_rgb, exists_rgb = torch.load(cache_rgb_path), True  # load\n",
            "/content/multispectral-object-detection/utils/datasets.py:921: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cache_ir, exists_ir = torch.load(cache_ir_path), True  # load\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning RGB 'dataset/color/color_train.cache' images and labels... 905 found, 0 missing, 0 empty, 0 corrupted: 100% 905/905 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning IR 'dataset/ir/ir_train.cache' images and labels... 905 found, 0 missing, 0 empty, 0 corrupted: 100% 905/905 [00:00<?, ?it/s]\n",
            "0.0\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning RGB 'dataset/color/color_valid.cache' images and labels... 302 found, 0 missing, 0 empty, 0 corrupted: 100% 302/302 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning IR 'dataset/ir/ir_valid.cache' images and labels... 302 found, 0 missing, 0 empty, 0 corrupted: 100% 302/302 [00:00<?, ?it/s]\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.78, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp2\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/114 [00:00<?, ?it/s]/content/multispectral-object-detection/train.py:751: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=cuda):\n",
            "      0/49     3.85G   0.09122   0.04215         0    0.1334         9       640: 100% 114/114 [01:39<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95:   0% 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:13<00:00,  1.42it/s]\n",
            "                 all         302         756     0.00906       0.722     0.00743    6.39e-06      0.0012\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     12.6G   0.08172   0.04277         0    0.1245         2       640: 100% 114/114 [01:24<00:00,  1.35it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:10<00:00,  1.86it/s]\n",
            "                 all         302         756     0.00639       0.541     0.00444    0.000275     0.00088\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/49     13.5G   0.07968   0.04331         0     0.123         2       640: 100% 114/114 [01:22<00:00,  1.39it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.91it/s]\n",
            "                 all         302         756     0.00617       0.624     0.00422    1.53e-05    0.000718\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/49     13.5G   0.07764   0.04216         0    0.1198         2       640: 100% 114/114 [01:23<00:00,  1.37it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:10<00:00,  1.86it/s]\n",
            "                 all         302         756      0.0074       0.668     0.00603    4.76e-05     0.00112\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/49     13.5G     0.075   0.04247         0    0.1175         2       640: 100% 114/114 [01:21<00:00,  1.40it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:10<00:00,  1.85it/s]\n",
            "                 all         302         756     0.00838       0.415     0.00694     2.1e-05     0.00121\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/49     13.5G   0.07207   0.04302         0    0.1151         3       640: 100% 114/114 [01:21<00:00,  1.39it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:10<00:00,  1.77it/s]\n",
            "                 all         302         756       0.116       0.118      0.0509       0.002     0.00898\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/49     13.5G   0.07017   0.03706         0    0.1072         2       640: 100% 114/114 [01:21<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:10<00:00,  1.86it/s]\n",
            "                 all         302         756      0.0955        0.25      0.0602    6.71e-05     0.00874\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/49     13.5G    0.0668    0.0346         0    0.1014         2       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:10<00:00,  1.81it/s]\n",
            "                 all         302         756       0.361        0.52       0.361     0.00824       0.081\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/49     13.5G   0.06355   0.03133         0   0.09488         1       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.95it/s]\n",
            "                 all         302         756       0.424       0.479       0.394      0.0191       0.108\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/49     13.5G   0.05672   0.02898         0   0.08569         1       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.99it/s]\n",
            "                 all         302         756       0.446       0.488        0.41     0.00352      0.0835\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/49     13.5G   0.05459   0.02662         0   0.08122         3       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.97it/s]\n",
            "                 all         302         756        0.86       0.765       0.816      0.0971       0.293\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/49     13.5G   0.05172   0.02539         0   0.07711         6       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.97it/s]\n",
            "                 all         302         756       0.883       0.786       0.841       0.166       0.332\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/49     13.5G   0.04872   0.02383         0   0.07256         0       640: 100% 114/114 [01:19<00:00,  1.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.99it/s]\n",
            "                 all         302         756       0.907       0.814       0.876       0.209       0.358\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/49     13.5G   0.04603   0.02216         0   0.06819         1       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.10it/s]\n",
            "                 all         302         756       0.902       0.805       0.855       0.117       0.317\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/49     13.5G   0.04593   0.02313         0   0.06906         4       640: 100% 114/114 [01:21<00:00,  1.40it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.04it/s]\n",
            "                 all         302         756       0.915        0.84        0.91       0.316       0.426\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/49     13.5G   0.04455   0.02196         0    0.0665         5       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.01it/s]\n",
            "                 all         302         756       0.909       0.864       0.906       0.372       0.435\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/49     13.5G   0.04241   0.02171         0   0.06412         7       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.97it/s]\n",
            "                 all         302         756       0.905       0.891       0.925       0.369       0.438\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/49     13.5G   0.04042   0.02165         0   0.06207         1       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.99it/s]\n",
            "                 all         302         756       0.938       0.881       0.936       0.477       0.498\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/49     13.5G   0.04067   0.02097         0   0.06163         1       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.04it/s]\n",
            "                 all         302         756        0.93       0.866       0.928       0.494         0.5\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/49     13.5G   0.04045   0.02024         0   0.06069         5       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.09it/s]\n",
            "                 all         302         756       0.929       0.899       0.944       0.489       0.502\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/49     13.5G   0.03909   0.02082         0   0.05991         3       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.06it/s]\n",
            "                 all         302         756       0.925       0.882       0.933       0.547        0.53\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/49     13.5G    0.0386   0.02024         0   0.05884         3       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.00it/s]\n",
            "                 all         302         756       0.944       0.887       0.948       0.544       0.531\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/49     13.5G   0.03753   0.01959         0   0.05711         1       640: 100% 114/114 [01:21<00:00,  1.40it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.92it/s]\n",
            "                 all         302         756       0.929       0.901        0.94       0.503       0.503\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/49     13.5G   0.03662   0.01902         0   0.05563         3       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.01it/s]\n",
            "                 all         302         756       0.932       0.873       0.935       0.552       0.534\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/49     13.5G   0.03713    0.0195         0   0.05664         7       640: 100% 114/114 [01:19<00:00,  1.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.02it/s]\n",
            "                 all         302         756       0.938       0.899       0.946       0.577       0.539\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/49     13.5G   0.03469   0.01906         0   0.05375         2       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.05it/s]\n",
            "                 all         302         756       0.928       0.905       0.946       0.564       0.534\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/49     13.5G   0.03614   0.01963         0   0.05577        10       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.05it/s]\n",
            "                 all         302         756       0.939       0.914       0.953       0.608       0.568\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/49     13.5G   0.03464   0.01911         0   0.05375         4       640: 100% 114/114 [01:19<00:00,  1.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.00it/s]\n",
            "                 all         302         756       0.933       0.902       0.948       0.594       0.551\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/49     13.5G   0.03446   0.01817         0   0.05263         2       640: 100% 114/114 [01:21<00:00,  1.40it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.04it/s]\n",
            "                 all         302         756       0.938       0.895       0.952       0.555       0.545\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/49     13.5G    0.0339   0.01867         0   0.05257         6       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.97it/s]\n",
            "                 all         302         756       0.934       0.905       0.948       0.641       0.561\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/49     13.5G   0.03275   0.01809         0   0.05084         1       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.98it/s]\n",
            "                 all         302         756        0.94       0.898       0.948         0.6       0.555\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/49     13.5G   0.03254   0.01788         0   0.05042         1       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.05it/s]\n",
            "                 all         302         756       0.934       0.922       0.956       0.581        0.54\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/49     13.5G   0.03364   0.01829         0   0.05192         6       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.03it/s]\n",
            "                 all         302         756       0.949       0.911       0.955       0.644       0.576\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/49     13.5G   0.03257   0.01795         0   0.05052         7       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.05it/s]\n",
            "                 all         302         756       0.932       0.907       0.958       0.615       0.569\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/49     13.5G   0.03198   0.01849         0   0.05046         8       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.00it/s]\n",
            "                 all         302         756       0.926        0.92       0.956        0.61       0.565\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/49     13.5G   0.03148    0.0168         0   0.04828         3       640: 100% 114/114 [01:21<00:00,  1.39it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.03it/s]\n",
            "                 all         302         756       0.933       0.923        0.96       0.626       0.577\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/49     13.5G   0.03174   0.01709         0   0.04883         7       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.98it/s]\n",
            "                 all         302         756       0.929        0.93       0.965       0.624       0.577\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/49     13.5G   0.03103   0.01754         0   0.04857        13       640: 100% 114/114 [01:19<00:00,  1.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.05it/s]\n",
            "                 all         302         756       0.949       0.914       0.964       0.636       0.581\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/49     13.5G   0.03017   0.01569         0   0.04586         4       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.98it/s]\n",
            "                 all         302         756       0.942        0.91       0.956       0.643       0.579\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/49     13.5G   0.03075   0.01667         0   0.04743         4       640: 100% 114/114 [01:19<00:00,  1.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.00it/s]\n",
            "                 all         302         756       0.953       0.909       0.962       0.655       0.584\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/49     13.5G   0.03009   0.01746         0   0.04756         7       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.05it/s]\n",
            "                 all         302         756       0.948        0.91       0.962       0.649       0.586\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/49     13.5G   0.02869   0.01663         0   0.04532         1       640: 100% 114/114 [01:19<00:00,  1.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.01it/s]\n",
            "                 all         302         756       0.939       0.913       0.956       0.632       0.575\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/49     13.5G   0.02915   0.01674         0   0.04589        10       640: 100% 114/114 [01:19<00:00,  1.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.97it/s]\n",
            "                 all         302         756       0.952       0.907        0.96        0.64       0.579\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/49     13.5G   0.02951   0.01585         0   0.04536         5       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.07it/s]\n",
            "                 all         302         756       0.952       0.915       0.969       0.628       0.574\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/49     13.5G   0.02851   0.01646         0   0.04497         2       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.09it/s]\n",
            "                 all         302         756       0.958       0.911       0.965        0.64       0.581\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/49     13.5G   0.02908   0.01745         0   0.04652        15       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.99it/s]\n",
            "                 all         302         756       0.949       0.909        0.96       0.652       0.585\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/49     13.5G   0.02838   0.01586         0   0.04424         4       640: 100% 114/114 [01:20<00:00,  1.41it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.04it/s]\n",
            "                 all         302         756       0.944       0.918       0.962        0.66       0.582\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/49     13.5G   0.02895    0.0161         0   0.04505         3       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  2.06it/s]\n",
            "                 all         302         756       0.948       0.893       0.959       0.649        0.58\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/49     13.5G   0.02832   0.01606         0   0.04438         3       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:09<00:00,  1.98it/s]\n",
            "                 all         302         756        0.94       0.917        0.96       0.655       0.585\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/49     13.5G   0.02706   0.01537         0   0.04242         1       640: 100% 114/114 [01:20<00:00,  1.42it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95:   5% 1/19 [00:00<00:11,  1.60it/s]Exception in thread Thread-5 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/multispectral-object-detection/utils/plots.py\", line 164, in plot_images\n",
            "    mosaic[block_y:block_y + h, block_x:block_x + w, :] = img\n",
            "ValueError: could not broadcast input array from shape (640,640,6) into shape (640,640,3)\n",
            "Exception in thread Thread-6 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/multispectral-object-detection/utils/plots.py\", line 164, in plot_images\n",
            "    mosaic[block_y:block_y + h, block_x:block_x + w, :] = img\n",
            "ValueError: could not broadcast input array from shape (640,640,6) into shape (640,640,3)\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95:  11% 2/19 [00:01<00:11,  1.42it/s]Exception in thread Thread-8 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/multispectral-object-detection/utils/plots.py\", line 164, in plot_images\n",
            "    mosaic[block_y:block_y + h, block_x:block_x + w, :] = img\n",
            "ValueError: could not broadcast input array from shape (640,640,6) into shape (640,640,3)\n",
            "Exception in thread Thread-7 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/multispectral-object-detection/utils/plots.py\", line 164, in plot_images\n",
            "    mosaic[block_y:block_y + h, block_x:block_x + w, :] = img\n",
            "ValueError: could not broadcast input array from shape (640,640,6) into shape (640,640,3)\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95:  16% 3/19 [00:02<00:12,  1.32it/s]Exception in thread Thread-9 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/multispectral-object-detection/utils/plots.py\", line 164, in plot_images\n",
            "    mosaic[block_y:block_y + h, block_x:block_x + w, :] = img\n",
            "ValueError: could not broadcast input array from shape (640,640,6) into shape (640,640,3)\n",
            "Exception in thread Thread-10 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/multispectral-object-detection/utils/plots.py\", line 164, in plot_images\n",
            "    mosaic[block_y:block_y + h, block_x:block_x + w, :] = img\n",
            "ValueError: could not broadcast input array from shape (640,640,6) into shape (640,640,3)\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 19/19 [00:10<00:00,  1.86it/s]\n",
            "                 all         302         756       0.936       0.922       0.962       0.632       0.579\n",
            "50 epochs completed in 1.536 hours.\n",
            "\n",
            "/content/multispectral-object-detection/utils/general.py:548: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x = torch.load(f, map_location=torch.device('cpu'))\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 413.4MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 413.4MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights /content/multispectral-object-detection/runs/train/exp2/weights/best.pt"
      ],
      "metadata": {
        "id": "1FPr0eD-CrYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --weights runs/train/exp2/weights/best.pt --data data/multispectral/LLVIP.yaml  --batch-size 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vLQM31rd5VE",
        "outputId": "d6d29814-997a-4304-8d19-5e0921a64b48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/exp2/weights/best.pt'], data='data/multispectral/LLVIP.yaml', batch_size=8, img_size=640, conf_thres=0.001, iou_thres=0.5, task='val', device='', single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project='runs/test', name='exp', exist_ok=False)\n",
            "data/multispectral/LLVIP.yaml\n",
            "YOLOv5 ðŸš€ 914f937 torch 2.5.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n",
            "\n",
            "/content/multispectral-object-detection/models/experimental.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(w, map_location=map_location)  # load\n",
            "Fusing layers... \n",
            "Model Summary: 1015 layers, 206198710 parameters, 0 gradients\n",
            "val\n",
            "/content/multispectral-object-detection/utils/datasets.py:908: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cache_rgb, exists_rgb = torch.load(cache_rgb_path), True  # load\n",
            "/content/multispectral-object-detection/utils/datasets.py:921: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cache_ir, exists_ir = torch.load(cache_ir_path), True  # load\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning RGB 'dataset/color/color_valid.cache' images and labels... 302 found, 0 missing, 0 empty, 0 corrupted: 100% 302/302 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning IR 'dataset/ir/ir_valid.cache' images and labels... 302 found, 0 missing, 0 empty, 0 corrupted: 100% 302/302 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5     mAP@.75  mAP@.5:.95: 100% 38/38 [00:12<00:00,  3.07it/s]\n",
            "                 all         302         756       0.941       0.927       0.963       0.662       0.582\n",
            "Speed: 28.3/3.5/31.8 ms inference/NMS/total per 640x640 image at batch-size 8\n",
            "Results saved to runs/test/exp\n",
            "302 labels saved to runs/test/exp/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xesupJSIKIit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}